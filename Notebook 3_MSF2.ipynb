{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Finance with Python\n",
    "\n",
    "### Alan Moreira, University of Rochester Simon Graduate School of Business\n",
    "\n",
    "# Notebook 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics covered\n",
    "* * *\n",
    " * Return distributions and moments of a return distribution\n",
    " * Annualization of returns\n",
    " * Log returns\n",
    " * Excess returns and risk premiums\n",
    " * Variances and Covariances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10061] Áî±‰∫éÁõÆÊ†áËÆ°ÁÆóÊú∫ÁßØÊûÅÊãíÁªùÔºåÊó†Ê≥ïËøûÊé•„ÄÇ>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1317\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[1;32m-> 1318\u001b[1;33m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[0;32m   1319\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1238\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1284\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1233\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1234\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1026\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    963\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    935\u001b[0m         self.sock = self._create_connection(\n\u001b[1;32m--> 936\u001b[1;33m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[0;32m    937\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    712\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m             \u001b[1;31m# Break explicitly a reference cycle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] Áî±‰∫éÁõÆÊ†áËÆ°ÁÆóÊú∫ÁßØÊûÅÊãíÁªùÔºåÊó†Ê≥ïËøûÊé•„ÄÇ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3af08425033e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#GlobalFinMonthly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"https://www.dropbox.com/s/3k35mt3t57ygff2/GlobalFinMonthly.csv?dl=1\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m99\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# tell python Date is date:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m     filepath_or_buffer, _, compression = get_filepath_or_buffer(\n\u001b[1;32m--> 392\u001b[1;33m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[0;32m    393\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'compression'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Content-Encoding'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'gzip'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[1;32m--> 544\u001b[1;33m                                   '_open', req)\n\u001b[0m\u001b[0;32m    545\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1359\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[1;32m-> 1361\u001b[1;33m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\program_files\\anaconda\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1318\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0;32m   1319\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10061] Áî±‰∫éÁõÆÊ†áËÆ°ÁÆóÊú∫ÁßØÊûÅÊãíÁªùÔºåÊó†Ê≥ïËøûÊé•„ÄÇ>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#GlobalFinMonthly\n",
    "url=\"https://www.dropbox.com/s/3k35mt3t57ygff2/GlobalFinMonthly.csv?dl=1\"\n",
    "Data = pd.read_csv(url,na_values=-99)\n",
    "# tell python Date is date:\n",
    "Data['Date']=pd.to_datetime(Data['Date'])\n",
    "# set an an index\n",
    "Data=Data.set_index(['Date'])\n",
    "\n",
    "Data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Distribution of Returns\n",
    "\n",
    "Lets start by looking at the moments of the distribution of returns for the \"market\" portfolio\n",
    "\n",
    "This is really the portfolio of all the stocks listed in the United States\n",
    "\n",
    "To be more precise it the value-weighted basket of these stocks\n",
    "\n",
    "What does value weighted mean?\n",
    "\n",
    "# $$w_{i,t}=\\frac{Price_{i,t}*NShares_{i,t}}{\\sum_{i=1}^I Price_{i,t}*NShares_{i,t}}$$\n",
    "\n",
    "What is i and I?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# looking at it's mean\n",
    "Data['MKT'].mean()\n",
    "\n",
    "# what does this number  mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# looking at the market standard deviation\n",
    "\n",
    "Data['MKT'].std()\n",
    "\n",
    "# what does it number mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# to have a sense of what that means lets look at the histgram of the distribution of retruns\n",
    "\n",
    "Data.MKT.hist(bins=50)\n",
    "\n",
    "# what do we see?\n",
    "\n",
    "# # centered around the mean, the amount of variation around the center is captured by the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Data.MKT.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random variables\n",
    "\n",
    "* We think of the return realization, the numbers plotted above, as a random variable, i.e., a variable that we are uncertain about it's realization. \n",
    "\n",
    "* Random variable is any thing that we don‚Äôt known\n",
    "\n",
    "  * Outcome of dice throw, value of stock market in the end of the day, ‚Ä¶\n",
    "  * For example a dice outcome is a rando variables with the following possible outcomes: (1,2,3,4,5,6)\n",
    "\n",
    "* This uncertianty is fully described by the probability distribution associated with the random variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a probability distribution?\n",
    "\n",
    "* A probability distribution describes the probability that each outcome is realized.\n",
    "* It can be described by a Probability Density Function (pdf).\n",
    "* For a example, the pdf of a dice is (1,1/6) ,(2,1/6), (3,1/6), (4,1/6), (5,1/6), (6,1/6)\n",
    "* It can also be described by the Cumulative Density Function(cdf)\n",
    "* For a example, the pdf of a dice is (1,1/6) ,(2,2/6), (3,3/6), (4,4/6), (5,5/6), (6,6/6)\n",
    "* A pdf or cdf fully describes the uncertainty we have with respect to a particular random variable\n",
    "* Random variable is any thing that we don‚Äôt known\n",
    "* Outcome of dice throw, value of stock market in the end of the day, ‚Ä¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moments\n",
    "\n",
    "* One way to summarize the information in a probability distribution is the moments\n",
    "\n",
    "* Mean or expected value $E[ùë•]=‚àëùë•_ùëñ ùëÉùëüùëúùëè(ùë•=ùë•_ùëñ )$  ùëúùëü $‚à´ùë•ùëì(ùë•)ùëëùë•$  often use ¬µ as symbol\n",
    "\n",
    "* The Variance $ùë£ùëéùëü(ùë•)= ‚àë(ùë•_ùëñ‚àíùê∏[ùë•])^2 ùëÉùëüùëúùëè(ùë•=ùë•_ùëñ )$    ùëúùëü $‚à´(ùë•_ùëñ‚àíùê∏[ùë•])^2 ùëì(ùë•)ùëëùë• $ \n",
    "  \n",
    "  * (Standard deviation $std(x)= \\sqrt{ùë£ùëéùëü(ùë•)}$)\n",
    "  * measures average variability around the mean across successive drawings of x.\n",
    "  * often use ùúé as a symbol for standard deviation and $ùúé^2$ for variance\n",
    "\n",
    "* Skewness $ùë†ùëòùëíùë§(ùë•)= ‚àë(ùë•_ùëñ‚àíùê∏[ùë•])^3 ùëÉùëüùëúùëè(ùë•=ùë•_ùëñ )$ ùëúùëü $‚à´(ùë•_ùëñ‚àíùê∏[ùë•])^3 ùëì(ùë•)ùëëùë•$\n",
    "  \n",
    "  * Measures asymmetry in the distribution\n",
    "\n",
    "* Kurtosis $ùëòùë¢ùëüùë°(ùë•)= ‚àë(ùë•_ùëñ‚àíùê∏[ùë•])^4 ùëÉùëüùëúùëè(ùë•=ùë•_ùëñ )$ ùëúùëü $‚à´(ùë•_ùëñ‚àíùê∏[ùë•])^4 ùëì(ùë•)ùëëùë•$ \n",
    "\n",
    "  * Measures how fat are the tails\n",
    "\n",
    "* Higher order moments‚Ä¶\n",
    "\n",
    "* Observation: with enough moments you can represent any distribution, but in practice you only need a few\n",
    "  \n",
    "  * for example for the normal distribution you only need the first two: Expected value and variance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample moments\n",
    "\n",
    "* Moments are  **never** truly known in real data\n",
    "\n",
    "* Must be always estimated from same sample of the data\n",
    "\n",
    "* We would like to know the \"population\" moments, i.e., the moments that describe how the population is generated\n",
    "\n",
    "* For example to get the expected return on the market, i.e. it's population mean, we use the sample mean\n",
    "\n",
    "$$\\overline{R_{MKT}}=\\frac{\\sum_{t=1}^TR_{MKT}}{T}$$\n",
    "\n",
    "* where T is the sample size\n",
    "* we also call the sample average\n",
    "\n",
    "* Note that each observation in the sample is weighted  equally by the frequency of the **realized** observations\n",
    "\n",
    "* For population means they are weighted by the **expected** frequency, i.e. the probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are returns normal?\n",
    "\n",
    "* Most of what we do does not depend on the assumption of normality\n",
    "\n",
    "* But normal distributions are very useful in statistical tests\n",
    "\n",
    "* And they are also not a bad approximation for return data at low frequency (monthly/year) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Normal distribution\n",
    "\n",
    "* Probability that any rando draw form a Normal distrivution random variable $\\tilde{x}$ is within $n=1$ standard deviation from the mean is 0.6826\n",
    "\n",
    "\n",
    "$$Prob(E[\\tilde{x}]-n\\sigma(\\tilde{x})\\leq \\tilde{x}\\leq (E[\\tilde{x}]+n\\sigma(\\tilde{x}))|_{n=1}=0.6826$$\n",
    "\n",
    "* $n=2,Prob(\\cdot)=0.9550$\n",
    "\n",
    "* it is convenient to to transform a normally distributed r.v. into units of stadard deviatio from it's mean\n",
    "\n",
    "\n",
    "$$\\tilde{z}=\\frac{\\tilde{x}-E[\\tilde{x}]}{\\sigma(\\tilde{x})}$$\n",
    "\n",
    "* This follow the \"standard\" normal distribution, which has mean 0 and and standard deviation 1 \n",
    "\n",
    "* can you show that is indeed the case that z has mean zero and standard devaiton 1? \n",
    "\n",
    "* This means that the normal distribution is completely characterized by it's first two moments\n",
    "\n",
    "* This means that the investment problem is much more tractable too!\n",
    "\n",
    "* Only two moments to worry about:\n",
    "\n",
    "    * The expected return of the portfolio\n",
    "    \n",
    "    * it's variance\n",
    "    \n",
    "    * The probability of really bad tail events will follow immediately from these two! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a return?\n",
    "\n",
    "* So we know what the normal distribution is\n",
    "\n",
    "* but what exactly is a return?\n",
    "\n",
    "* Lets say you paid ùëÉ_ùë° in date t for a stock\n",
    "\n",
    "* In date t+1 the price is ùëÉ_(ùë°+1)  and you earn some dividend as well ùê∑_(ùë°+1)\n",
    "\n",
    "* Then we say that your return is\n",
    "\n",
    "$$ùëÖ_{ùë°+1}=\\frac{ùëÉ_{ùë°+1}+ùê∑_{ùë°+1}‚àíùëÉ_ùë°}{ùëÉ_ùë°}$$\n",
    "\n",
    "* It is the gain you made, divided by how much you put in\n",
    "\n",
    "> Our data set Data contains these returns of buying an asset, earning any distributed dividends during the month, and then selling in the end of the month.\n",
    "\n",
    ">As we will see, the return on a portfolio is just a weighthed average of the returns of the individual assets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to evaluate whether returns are normal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The standard approach is to look at higher moments.\n",
    "\n",
    "Because the normal is entired descibed by the frist two moments, looking at these higher moments can gives us a clue if that is really true for the data at hand.\n",
    "\n",
    "Here are a few:\n",
    "\n",
    "* Skewness \n",
    "\n",
    "* Kurtosis \n",
    "\n",
    "* Frequency of extreme return realizations \n",
    "\n",
    "  * 3 sigma events should almost never happen for a normal random variable\n",
    "  \n",
    "  * once every 500 periods\n",
    "\n",
    "  $$PROB(|R-E{R}|>3\\sigma(R))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A nice thing to do is to simulate data generated by a normal with same sample mean and standard deviation as the normal, and compare it with the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# lets look at a simulation to see this more clearly\n",
    "\n",
    "\n",
    "mu=Data.MKT.mean()\n",
    "std=Data.MKT.std()\n",
    "T=Data.MKT.count()\n",
    "X=pd.Series(np.random.normal(mu,std,T))\n",
    "Data.MKT.hist(bins=50)\n",
    "\n",
    "X.hist(bins=50)\n",
    "# what happens if we increase the mean?\n",
    "\n",
    "# what happens if we increase the standard deviation?\n",
    "\n",
    "# for the same standard mean and standard deviation what do you notice when you compare the real data and the simulated data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# To evaluate how close a distribution is to the normal distribution we typically look at\n",
    "\n",
    "# skewness\n",
    "\n",
    "[Data.MKT.skew(), X.skew()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# To evaluate how close a distribution is to the normal distribution we typically look at\n",
    "\n",
    "# kurtosis\n",
    "[Data.MKT.kurtosis(),X.kurtosis()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold=3\n",
    "X=pd.Series(np.random.normal(mu,std,T))\n",
    "# counts for the real data\n",
    "A=((Data.MKT-Data.MKT.mean())<-threshold*Data.MKT.std())\n",
    "# counts for simulated data (which we know it is normal!)\n",
    "B=((X-X.mean())<-threshold*X.std())\n",
    "\n",
    "[A.sum(),B.sum()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log returns (also called continously compounded) and Simple returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at also at log returns\n",
    "\n",
    "Insight: If innovations in log returns are iid then, log returns at long enough horizons must be normal (Central Limit Theorem)\n",
    "\n",
    "$$1+ùëÖ_{1‚Üíùëá}=((1+ùëÖ_1 )(1+ùëÖ_2 )‚Ä¶(1+ùëÖ_ùëá))‚Å°\\\\\n",
    "ln‚Å°(1+ùëÖ_{1‚Üíùëá} )=ln‚Å°((1+ùëÖ_1 )(1+ùëÖ_2 )‚Ä¶(1+ùëÖ_ùëá ))\\\\\n",
    "ln‚Å°(1+ùëÖ_{1‚Üíùëá} )=ln‚Å°(1+ùëÖ_1 )+ln‚Å°(1+ùëÖ_2 )+‚Ä¶+ln‚Å°(1+ùëÖ_ùëá )\\\\\n",
    "                    ùëü_{ùë°‚Üíùëá}=ùëü_1+ùëü_2+‚Ä¶+ùëü_ùëá $$ \n",
    "\n",
    "\n",
    "\n",
    "* Thus, if T is large,$ùëü_{ùë°‚Üíùëá}$ will be approximately normally distributed. (central limit theorem)\n",
    "\n",
    "* $ùëü_ùë°=ln‚Å°(1+ùëÖ_ùë° )$ is the rate of return assuming continuous compounding for the period t.\n",
    "\n",
    "* This turns out to hold up well if you look at horizons longer than a month, but does not work at all at daily frequency (much fatter left tail than the normal distribution predicts)\n",
    "\n",
    "\n",
    "* Log returns are also very convenient when thinking about long-term investing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "np.log(1+Data.MKT).hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print([np.log(1+Data.MKT).skew(),X.skew()])\n",
    "\n",
    "print([np.log(1+Data.MKT).kurtosis(),X.kurtosis()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to go back and fourth log and simple returns?\n",
    "\n",
    "Let R be a simple net return per period, i.e., if you invest 10 , you get 10(1+R) in the end of the period\n",
    "\n",
    "R is a number like 5% (0.05)\n",
    "\n",
    "We say 1+R, a number like 1.05 is a gross return. \n",
    "\n",
    "Why gross? Because it includes 1, your initial investment.\n",
    "\n",
    "To get log returns r=log(1+R)\n",
    "\n",
    "\n",
    "To get back simple returns\n",
    "\n",
    "R=exp(r)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r=np.log(1+Data.MKT)\n",
    "R=np.exp(r)-1\n",
    "pd.concat([R,Data.MKT],axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "threshold=2\n",
    "# now real data in log returns\n",
    "\n",
    "A=((np.log(Data.MKT+1)-np.log(Data.MKT+1).mean())<-threshold*np.log(Data.MKT+1).std())\n",
    "B=((X-X.mean())<-threshold*X.std())\n",
    "[A.sum(),B.sum()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 5 9/9 ended here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical package\n",
    "\n",
    "We can also do the computation precisely  without using a simulation which is the way we will typically do.\n",
    "\n",
    "For that we will import the normal density function using the SCIPY library\n",
    "\n",
    "\n",
    "SCIPY\n",
    " - This is a stats package\n",
    " - It has a lot of stuff in it\n",
    " - I will talk about only the stuff we need \n",
    " - But feel free to have fun\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Here I am only importing the normal distribution\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# I will use the MKT sample moments to calibrate the distribution so we can compare apples to apples\n",
    "mu,sigma=Data.MKT.mean(),Data.MKT.std()\n",
    "# and I am creating this p object which is the standard normal distribution\n",
    "p=norm(Data.MKT.mean(),Data.MKT.std())\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here what that looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# creating a grid to evaluate the density around the relevant range (-6 to +6 std relative to the mean)\n",
    "grid=np.linspace(mu-6*sigma,mu+6*sigma,1000)\n",
    "\n",
    "#Plot the normal density for this range \n",
    "plt.plot(grid, p.pdf(grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(grid, p.cdf(grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "threshold=3\n",
    "Below=((Data.MKT-Data.MKT.mean())<-threshold*Data.MKT.std())\n",
    "Above=((Data.MKT-Data.MKT.mean())>threshold*Data.MKT.std())\n",
    "T=Data.MKT.count()\n",
    "[Below.sum(),Above.sum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# However it is often more covenient to work with the standard normal distribution\n",
    "ps=norm(0,1)\n",
    "probm=ps.cdf(-threshold)\n",
    "probp=1-ps.cdf(threshold)\n",
    "print('The probability of such extreme tail events')\n",
    "print([probm,probp])\n",
    "print('The number of such extreme tail events we expect in a sample as large as ours')\n",
    "print([probm*T,probp*T])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence Intervals and T-tests\n",
    "\n",
    "We often will use the opposite operation:\n",
    "\n",
    "* given a probability , lets say P=5%, we want to know the value X for which there is less than P probability that some reference distribution produces a value as high as X.\n",
    "\n",
    "* Given that we observed X, P gives us the likelihood that X came from this reference distribution\n",
    "\n",
    "* This reference distribution is our NULL-Hypothesis\n",
    "\n",
    "* For example, lets say our null hypothesis is that the market returns are normally distributed with a certain mean and standard deviation. \n",
    "\n",
    "* IF you observe X, how low X would have to be for the probability that X was sampled from this reference distribution is less than, say, 1%?\n",
    "\n",
    "* The function that answers this question is the inverse cdf which we call using .isf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# here for the standard normal\n",
    "\n",
    "#So, the observation would have to be below the mean by the follow number of standard deviations\n",
    "\n",
    "ps.isf(0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(grid, p.pdf(grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is a \"one-sided\" test.\n",
    "\n",
    "* You can also have asked\" how extreme (either way) X would have to be so that the probability that it came from a normal with such mean/standard-deviation\n",
    "\n",
    "* This would lead to a two-sided test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "ps.isf(0.01/2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we observe such an extreme observation we would say that we can reject the reference distribution with a confidence of 99% or a pvalue of 1%.\n",
    "\n",
    "* Of course, a formal test of whether a random variable is normally distributed for any mean and standard deviation is much more complicated and less powerful.\n",
    "\n",
    "* So it is not really used that much with financial data in practice.\n",
    "\n",
    ">But as practicioners is important to be aware of large deviations of normality specially at higher frequecies, daily returns, minute-to-minute returns\n",
    "\n",
    "* We will revisit this once we work with daily data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The choice of frequency and Annualization of returns \n",
    "\n",
    "* The data that we get is structured at a particular frequency.\n",
    "\n",
    "* For example, the data set \"Data\" that we have been working with is at the \"monthly\" frequencies\n",
    "\n",
    "* So the returns there tell us what you would have earned if you bought a particular asset at the closing of the last Trading day of the month-say 31 of January and sold 28 of Ferbruary.\n",
    "\n",
    "* But this is Frequency choice is entirely arbitrary since there are transactions all the time\n",
    "\n",
    "* In this course we will work at monthly or daily frequency since that is what most practioners work with (exception of course for High Frequency trading funds)\n",
    "\n",
    "* It also keeps it managable--as you will quickly see that the data set can get very large once you go to higher frequencies\n",
    "\n",
    "* One could argue that monthly is too short. Most people have one year or ever multiple year investment plans so maybe it makes sense to look at the data at lower frequecies. There is metrit to this view, but you end up with much less data, so harder to make conclusive statements\n",
    "\n",
    "* What we end up doing in the academic world and in the industry is to make out analayis at monthly frquency, and we then extraploate the results to yearly and so on.\n",
    "\n",
    "* Now we will discuss how to do that.\n",
    "\n",
    "* For us this will be important, because it is much easier to kepe the units at the yearly frequency in your head. So we will be frequently annualize our results just to get intution about what they mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard annualization (the quick and dirty way)\n",
    "\n",
    "* $\\hat{\\mu}_A=12\\times\\hat{\\mu}_M$\n",
    "* $\\hat{\\sigma}^2_A=12\\times\\hat{\\sigma}^2_M$\n",
    "* $\\hat{\\sigma}_A=\\sqrt{12}\\times\\hat{\\sigma}_M$\n",
    "* $SR_A=\\frac{\\hat{\\mu}_A}{\\hat{\\sigma}_A}=\\sqrt{12}SR_M$\n",
    "\n",
    "> This last one is what we call the Sharpe ratio (for William Sharpe). It is a key moment that we will be looking at and the entire financial industry is organized around this moment.\n",
    "It measures how much return you get per unit of volatility\n",
    "\n",
    "* Formulas make sense if monthly returns are i.i.d. and a sum of monthly returns (e.g. log returns)\n",
    "\n",
    "* However, annual return are given by\n",
    "\n",
    "$ùëÖ_ùê¥=(1+ùëÖ_1 )(1+ùëÖ_2 )‚Ä¶(1+ùëÖ_{12})‚Å°‚àí1$\n",
    "\n",
    "* if returns were i.i.d, averages are\n",
    "\n",
    "$$\\mu_A=(1+\\mu_M)^{12}-1$$\n",
    "\n",
    "* and variances are uglier still,\n",
    "\n",
    "$$\\sigma_A^2=[\\sigma^2_M+(1+\\mu_M)^2]^{12}-(1+\\mu_M)^{24}$$\n",
    "\n",
    "* and this still ignores time-variation in volatility (very strong feature of the data!), auto-correlations  in returns (there is a little bit)\n",
    "\n",
    "#### However, we will always use the standard annualization\n",
    "\n",
    "* $\\hat{\\mu}_A=12\\times\\hat{\\mu}_M$\n",
    "* $\\hat{\\sigma}^2_A=12\\times\\hat{\\sigma}^2_M$\n",
    "* $\\hat{\\sigma}_A=\\sqrt{12}\\times\\hat{\\sigma}_M$\n",
    "* $SR_A=\\frac{\\hat{\\mu}_A}{\\hat{\\sigma}_A}=\\sqrt{12}SR_M$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# simply multiply by number of months in a year\n",
    "Data.MKT.mean()*12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# for standard deviation you multiply by the square root of number of periods since the varaince grows with T\n",
    "\n",
    "Data.MKT.var()*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Data.MKT.std()*12**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### If it is wrong, why we will use it?\n",
    "\n",
    "* Because it is the standard\n",
    "* good idea about annual magnitudes\n",
    "* allows you to compare across assets pretty well\n",
    "* easy to get t-stats from monthly data\n",
    "* ok if you don't compare returns across frequencies, i.e., use annual data for real estate, and monthly for stocks. \n",
    "\n",
    "* It would lead to incorrect conclusions\n",
    "\n",
    "* Lets say that you only have one asset at the yearly frequency, \n",
    "\n",
    "  * then you have to aggregate the monthly data set to yearly and the compute the moments\n",
    "\n",
    "  * This makes no assumptions and it is always right\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- For every year we want to compute the cumulative returns\n",
    "\n",
    "$$r_{year}=\\prod_{t \\in year} (1+r_t)-1$$\n",
    "\n",
    "In the end we want a table that looks like\n",
    "\n",
    "year|MKT...\n",
    "--|-\n",
    "1997|$r_{1997}$\n",
    "1998|$r_{1998}$\n",
    "1999|$r_{1999}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Here we are at the same time adding 1 to the return variable, so we have a gross return which we can compound\n",
    "#And also use the year of the observation to group all the year\n",
    "\n",
    "Datayear=(Data+1).groupby(Data.index.year).prod()-1\n",
    "# the last step is how we want to group\n",
    "# we could want to calculate the standard devition, the mean, the man, the min, or even to apply some custom fucntion\n",
    "# in our case all we need is the product\n",
    "\n",
    "# where we are substracting 1 to get back to a net return\n",
    "[Datayear.MKT.mean(),Data.MKT.mean()*12,Datayear.MKT.std(),Data.MKT.std()*12**0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Datayear.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In problem set I will always ask you about annual numbers\n",
    "\n",
    "- You should always go for the quick and dirty annualization unless told otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Excess returns and risk-premiums\n",
    "\n",
    "\n",
    "- it is convenient to decompose the return earned in terms of what you earn due \n",
    " \n",
    " 1. compensation for waiting (time-value of money)\n",
    " 2. compensation for bearing risk (risk premium)\n",
    " \n",
    " \n",
    " We call an \"excess return\", the return minus the risk-free rate \n",
    " \n",
    " $$R_i^e=R_i-R_f$$\n",
    " \n",
    " We typically use the returns of a 3-month treasury bill\n",
    " \n",
    "So the excess return of the market is\n",
    "\n",
    "$$R^e_{MKT}=R_{MKT}-R_f$$\n",
    "\n",
    "i.e. how much more I would get if I invested in the market instead of a short-term risk-free U.S. treasury bond\n",
    "\n",
    "We call the Expected difference, the risk-premium\n",
    "\n",
    "$$E[R_i^e]=E[R_i-R_f]$$\n",
    "\n",
    "It is how much more you expect to get by investing in asset i instead of the risk-free rate\n",
    "\n",
    "When asset i, is the total market portfolio of US equities, we call this, the equity risky premium\n",
    "\n",
    "Equity Risk premium\n",
    "\n",
    "$$E[R_{MKT}^e]=E[R_{MKT}-R_f]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "(Data.MKT-Data.RF).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "(Data.MKT-Data.RF).mean()*12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this mean?\n",
    "\n",
    "Lets look at how much money one would have if they had invested 1 dollar in the market and kept reinvesting until the end of our sample\n",
    "\n",
    "lets then compare with an investment in the risk-free rate\n",
    "\n",
    "$$(1+r_1)(1+r_2)....(1+r_T)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "(1+Data[['RF','MKT']]).cumprod().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that someone that invested 1 dollar in the market in 63, would have 175 dollars today.\n",
    "\n",
    "A tota return of 182/1-1=18,200\\%\n",
    "\n",
    "If you invested in the risk-free rate you would have\n",
    "\n",
    "12.5/1-1= 1,150\\% which is a bit above the inflation in this same period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "(1+Data[['RF','MKT']]).cumprod().tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk, Variances, and Covariances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know how to compute variance and what they are\n",
    "\n",
    "$$Data.MKT.std()=\\sqrt{\\sum_{t=1}^T\\frac{(R_{MKT,t}-\\overline{R_{MKT}})^2}{T}}$$\n",
    "\n",
    "where $\\overline{R_{MKT}}=\\sum_{t=1}^T\\frac{R_{MKT,t}}{T}$ is the sample mean.\n",
    "\n",
    "\n",
    "So for each series we get a number. We oftern refer to the standard deviation as the \"vol\" or the volatility of an asset.\n",
    "\n",
    "Variance and volatility have the same content, but volatility is int he same units as returns, and not square returns, so it easier (for me!) to have inution what it means.\n",
    "\n",
    "For example, if the market has a vol of 30% per year, I know that there is a 2.5% probability that I will loose 60% of my investments by the end of the year!\n",
    "\n",
    "So it is a great gauge of risk...at least at the portfolio level\n",
    "\n",
    "But when thinking about a specific stock, it's volatility means very little\n",
    "\n",
    "Unless your entire portfolio is just that stock, you don't really need to bear the stock risk--if you have 1% is a stock a stock drops 20% that is only 0.2% in your portfolio. You will not even noticed either way.\n",
    "\n",
    "\n",
    "#### But what risk should you care about? What stock should be risky for you?\n",
    "\n",
    "The great insight from Harry Markowitz was to think of risk in terms of what the stock adds given your portfolio\n",
    "\n",
    "Just like meat can be good for you if you are not eating any meat, it is terrible if you are eating a lot of it\n",
    "\n",
    "What investors should care about is, just like eaters, their final diet. If a given stock brings a lot of what you already have it, it will be bad for you, i.e., risky.\n",
    "\n",
    "The way to measure this degree of commonality between your portfolio and this particular stock is the covariance\n",
    "\n",
    "\n",
    "$$Cov(R_{i,t},R_{j,t})={\\sum_{t=1}^T\\frac{(R_{i,t}-\\overline{R_{i}})(R_{j,t}-\\overline{R_{j}})}{T}}$$\n",
    "\n",
    "\n",
    "The Covariance matrix of a set of stocks is the matrix where cell(i,j) has the covariance between asset i and asset j:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# here for two assets\n",
    "Data[['MKT','WorldxUSA']].cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that the diagonal, cell(i,i)nhas the covariance between asset i and asset i, which is just the variance of asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Data[['MKT','WorldxUSA']].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# here for all the assets except the risk-free rate\n",
    "\n",
    "Data.drop('RF',axis=1).cov()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of looking at this is the correlation matrix, which normalizes the covariances by the volatilities in each asset:\n",
    "\n",
    "$$Corr(R_{i,t},R_{j,t})={\\frac{Cov(R_{i,t},R_{j,t})}{\\sqrt{Var(R_{i,t})Var(R_{j,t})}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Data.drop('RF',axis=1).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is noteworthy about these relationships?\n",
    "\n",
    "* What is safer for an US investor US bond portfolio or World bond portfolio?\n",
    "\n",
    "* What is safer for an international investor US bond portfolio or World bond portfolio?\n",
    "\n",
    "* Why did I drop the risk-free rate to make these calculations?\n",
    "\n",
    "* Why did I drop RF, the risk-free rate, to compute the correlations? \n",
    "\n",
    "* In what sense the rate of return of the risk-free rate is different from the rate of return of these other assets?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
